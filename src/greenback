#!/usr/bin/python -B

"""
TODO LIST

NOW
~~~
[?] snazzy name
[ ] push to github
[x] config files (global, per machine, per share)
[x] use rsync instead of rsback
[x] rotate backups myself
[ ] write summary info to a per-backup status/history file
[x] plug-in to allow LED blinking
[x] store status in a file
[ ] second-level backups
[ ] bug?? : failures still update timestamp
[ ] debian package

LATER
~~~~~
audit runs after backup, compares "new" and "large" files to yesterday's large files, compares md5, creates hard links
"""

import os
import datetime
import subprocess
import shlex
import glob
import operator
import sys
from optparse import OptionParser
import time
import shutil
from configobj import ConfigObj         # apt-get install python-configobj
import imp
import errno


class DefaultsClass:
    def __init__ (self, *argv, **argd):
        self.__dict__.update (argd)

def enum(*sequential, **named):
    enums = dict(zip(sequential, range(len(sequential))), **named)
    return type('Enum', (), enums)


# globals
programName = 'greenback'
topdir = '/backup'
libdir = '/var/lib/'+programName
maxAge = 10000000
sleepMin = 10
# defaults (globals)
class defaults (DefaultsClass):
    lastBackupTimestamp = 0
    cycleSec = 24*60*60
    keepCount = 9
    label = 'daily'
# plumbing (globals)
options = ()
g_logFD = None
status = enum('UNKNOWN', 'NOT_READY', 'READY', 'SUCCEEDED', 'FAILED', 'DISABLED')

#-----------------------------------------------------------

def log_init():
    # we're writing these globals
    global g_logFD
    # log file
    #  logdir = os.environ['HOME']+"/var/log"
    #  if not os.path.exists(logdir):
    #     os.makedirs(logdir)
    #  logfile = logdir+"/garage.log"
    #  logfile = programName+'.log'
    logfile = '/dev/stdout'
    g_logFD = open(logfile,'a')

#-----------------------------------------------------------

def log_debug(string):
    if options.debug: log_info(string)

#-----------------------------------------------------------

def log_info(string):
    if options.quiet: return
    global g_logFD
    timeStamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    g_logFD.write(timeStamp+" "+string+"\n")
    g_logFD.flush()
    ##os.fsync(g_logFD)

#-----------------------------------------------------------

def shell_capture(cmdargs):
    global g_logFD
    log_debug('shell_capture command >> '+(' '.join(cmdargs)))
    p = subprocess.Popen(cmdargs, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    stdout, stderr = p.communicate()
    rc = p.returncode
    log_debug("shell_capture done, rc="+('%d'%rc))
    return rc, stdout, stderr

#-----------------------------------------------------------

def shell_do(cmdargs):
    global g_logFD
    log_debug('shell_do command >> '+(' '.join(cmdargs)))
    rc = subprocess.call(cmdargs)
    #rc = subprocess.call(cmdargs, stdout=g_logFD, stderr=g_logFD)
    log_debug("shell_do rc = "+("%d"%rc))
    return rc

#-----------------------------------------------------------

def sec2dhms(s):
    days = s // 86400  ; s = s - (days * 86400)
    hours = s // 3600  ; s = s - (hours * 3600)
    mins = s // 60     ; s = s - (mins * 60)
    secs = s
    return (days, hours, mins, secs)

#-----------------------------------------------------------

def mkdir_p(path):
    try:
        os.makedirs(path)
    except OSError as exc: # Python >2.5
        if exc.errno == errno.EEXIST and os.path.isdir(path):
            pass
        else: raise

#-----------------------------------------------------------

def write_status(doing,waitTime,target):
    log_debug('writing status file')
    statusFileName = libdir+'/status'
    statusFile = file(statusFileName,'w')
    now = datetime.datetime.now()
    statusFile.write('date='+datetime.datetime.strftime(now,'%Y-%m-%d')+'\n')
    statusFile.write('time='+datetime.datetime.strftime(now,'%H:%M:%S')+'\n')
    statusFile.write('pid='+str(os.getpid())+'\n')
    statusFile.write('wait='+str(waitTime)+'\n')
    statusFile.write('status='+doing+'\n')
    if target is None: target=''
    statusFile.write('target='+target+'\n')
    (total, used, free) = disk_usage(topdir)
    statusFile.write('disk.mntpt='+topdir+'\n')
    statusFile.write('disk.total='+str(total)+'\n')
    statusFile.write('disk.used='+str(used)+'\n')
    statusFile.write('disk.free='+str(free)+'\n')
    statusFile.close()

#-----------------------------------------------------------

def disk_usage(path):
    """Return disk usage statistics about the given path.

    Returned value is a tuple with three attributes:
    'total', 'used' and 'free' (in bytes).
    """
    st = os.statvfs(path)
    free = st.f_bavail * st.f_frsize
    total = st.f_blocks * st.f_frsize
    used = (st.f_blocks - st.f_bfree) * st.f_frsize
    return (total, used, free)

#-----------------------------------------------------------

def setParmString(cfgFile,cfgHash,cfgIdx,volHash,volIdx):
    if cfgIdx not in cfgHash: return False
    volHash[volIdx] = cfgHash[cfgIdx]
    log_info(' - '+cfgFile+': '+cfgIdx+'='+cfgHash[cfgIdx]+' >> STRING >> '+volIdx+'='+volHash[volIdx])
    return True

#-----------------------------------------------------------

def setParmInt(cfgFile,cfgHash,cfgIdx,volHash,volIdx,multiplier=1):
    if cfgIdx not in cfgHash: return False
    volHash[volIdx] = int(cfgHash[cfgIdx]) * multiplier
    log_info(' - '+cfgFile+': '+cfgIdx+'='+cfgHash[cfgIdx]+' >> INT >> '+volIdx+'='+str(volHash[volIdx]))
    return True

#-----------------------------------------------------------

def setParmBool(cfgFile,cfgHash,cfgIdx,volHash,volIdx):
    if cfgIdx not in cfgHash: return False
    if cfgHash[cfgIdx].lower() in ['yes','y','true','1']:
        log_debug('TRUE')
        volHash[volIdx] = True
    else:
        log_debug('FALSE')
        volHash[volIdx] = False
    log_info(' - '+cfgFile+': '+cfgIdx+'='+cfgHash[cfgIdx]+' >> BOOL >> '+volIdx+'='+( 'TRUE' if volHash[volIdx] else 'FALSE'))
    return True

#-----------------------------------------------------------

def buildVolumeTable():

    volumeInfo = []

    configFilename = topdir+'/config.py'
    try:
        config = imp.load_source('config', configFilename)
        log_debug("config file '"+configFilename+"' found")
        volumeInfo = config.volumeInfo
    except ImportError:
        log_debug("config file '"+configFilename+"' not found")
        pass

    # FILL IN THE 'volumeInfo' DICTIONARY

    for volume in volumeInfo:

        # set an index to refer to this entry by
        index = volume['host']+'-'+volume['name']
        volume['index'] = index

        # set some defaults - always
        volume['status'] = status.UNKNOWN
        volume['lastBackupTimestamp'] = defaults.lastBackupTimestamp
        volume['lastBackupDurationSec'] = 0
        # set some defaults - only if not set in config.py (TODO: change this)
        if 'label' not in volume: volume['label'] = defaults.label
        if 'cycleSec' not in volume: volume['cycleSec'] = defaults.cycleSec
        if 'keepCount' not in volume: volume['keepCount'] = defaults.keepCount
        if 'disabled' not in volume: volume['disabled'] = False

        # build a list of several optional config files to look for
        configFiles=[]
        configFiles.append(topdir+'/config') # /backup/config
        configFiles.append(topdir+'/'+volume['host']+'/config') # /backup/host/config
        configFiles.append(topdir+'/'+volume['host']+'/'+volume['name']+'/config') # /backup/host/name/config

        for configFile in configFiles:
            # read the config files if they exist
            if os.path.isfile(configFile):
                log_debug("reading config file '"+configFile+"'")
                config = ConfigObj(configFile)
                # STRING OPTIONS
                setParmString(configFile,config,'src',volume,'src')
                setParmString(configFile,config,'label',volume,'label')
                # NUMBER OPTIONS
                setParmInt(configFile,config,'cycleDay',volume,'cycleSec',86400)
                setParmInt(configFile,config,'cycleHour',volume,'cycleSec',3600)
                setParmInt(configFile,config,'cycleMin',volume,'cycleSec',60)
                setParmInt(configFile,config,'cycleSec',volume,'cycleSec')
                setParmInt(configFile,config,'keepCount',volume,'keepCount')
                # BOOLEAN OPTIONS
                setParmBool(configFile,config,'disabled',volume,'disabled')
            else:
                log_debug("no config file '"+configFile+"'")

    # LOOK AT RECENT BACKUPS

    # TODO - don't just read all files, start from config instead
    recentBackups = glob.glob(topdir+'/*/*/*.1')
    for recentBackup in recentBackups:
        # break the wildcard (glob) into parts
        junk1, junk2, right = recentBackup.partition(topdir)
        pathpieces = right.split('/')
        host = pathpieces[1]
        name = pathpieces[2]
        # Get the creation time of the daily.1 directory.
        # Note: ctime() does not refer to creation time on *nix systems,
        # but rather the last time the inode data changed.
        lastBackupTimestamp = datetime.datetime.fromtimestamp(os.path.getmtime(recentBackup))
        # find the volumeInfo line that contains key='host-name'
        try:
            idx = map(operator.itemgetter('index'), volumeInfo).index(host+'-'+name)
            log_debug('host='+host+', name='+name+', '+host+'-'+name+' is in slot %d'%idx)
            volumeInfo[idx]['lastBackupTimestamp'] = lastBackupTimestamp
        except ValueError:
            log_debug('host='+host+', name='+name+', '+host+'-'+name+' is not in the list of volumes')
            pass

    return volumeInfo

#-----------------------------------------------------------

def updateAgesAndSort(volumeInfo):

    # GO THROUGH THE LIST IN ORDER, DETERMINE THEIR AGES AND NEXT BACKUP TIME

    now = datetime.datetime.now()
    for volume in volumeInfo:
        ageDelta = now - volume['lastBackupTimestamp']
        volume['ageSec'] = ageDelta.seconds + (ageDelta.days * 86400)
        volume['nextBackupSec'] = volume['cycleSec'] - volume['ageSec']
        log_debug('index='+volume['index']+', nextBackupSec='+str(volume['nextBackupSec'])+'sec')
        # force disabled backups to the bottom of the list
        if volume['disabled']: volume['nextBackupSec'] = maxAge

    for volume in volumeInfo:
        if volume['status'] in (status.NOT_READY, status.UNKNOWN):
            # If "cycleSec" has transpired since our last backup, we're "ready".
            if volume['ageSec'] > volume['cycleSec']: volume['status'] = status.READY
            else: volume['status'] = status.NOT_READY
        # No matter if "ready" or not, if disabled, don't back up.
        if volume['disabled']: volume['status'] = status.DISABLED

    sortedVolumes = sorted(volumeInfo, key=operator.itemgetter('nextBackupSec'))

    return sortedVolumes

#-----------------------------------------------------------

def formattedTable(volumes):
    widths = { 'index':0, 'lastBackupTimestamp':0, 'ageSec':0, 'cycleSec':0 }
    for volume in volumes:
        for fld in ('index','ageSec','cycleSec'):
            widths[fld] = max(widths[fld], len(str(volume[fld])))
    #widths['lastBackupTimestamp'] = len('| 2013-03-20 21:05:18 | 1368/1440  |  NEXT RUN 0d+0:01:12')
    widths['lastBackupTimestamp'] = len('2013-03-20 21:05:18')

    table = []
    table.append(''
        + 'INDEX'.center(widths['index'])                     + '   '
        + 'LAST BACKUP'.center(widths['lastBackupTimestamp']) + '   '
        + 'AGE'.center(widths['ageSec'])                      + '/'
        + 'CYCLE'.center(widths['cycleSec'])                  + '   '
        + 'STATUS')

    now = datetime.datetime.now()
    for volume in volumes:
        (d,h,m,s) = sec2dhms( volume['nextBackupSec'] )
        nextBackupInterval = '%dd+%d:%02d:%02d' % (d,h,m,s)
        (d,h,m,s) = sec2dhms( volume['lastBackupDurationSec'] )  # assume 0 days
        lastBackupDurationSec = '%d:%02d:%02d' % (h,m,s)
        switch = {
            status.UNKNOWN:   '???',
            status.DISABLED:  'DISABLED',
            status.NOT_READY: 'NEXT RUN IN '+nextBackupInterval,
            status.READY:     'READY',
            status.SUCCEEDED: 'SUCCEEDED ('+lastBackupDurationSec+')',
            status.FAILED:    'FAILED ('+lastBackupDurationSec+')',
        }
        lastBackupTimestampString = volume['lastBackupTimestamp'].strftime('%Y-%m-%d %H:%M:%S')
        table.append(''
            + volume['index'].ljust(widths['index'])            + '   '
            + lastBackupTimestampString                         + '   '
            + str(volume['ageSec']).rjust(widths['ageSec'])     + '/'
            + str(volume['cycleSec']).ljust(widths['cycleSec']) + '   '
            + switch[volume['status']]
        )

    return table

#-----------------------------------------------------------

def tableToLogAndDisk(activity,volumeInfo):

    # CREATE A FORMATTED TABLE

    table = formattedTable(volumeInfo)
    date = datetime.datetime.strftime(datetime.datetime.now(),'%Y-%m-%d %H:%M:%S')

    # DUMP THE SORTED LIST IN A TEXT FILE

    tableFileName = libdir+'/queue'
    tableFile = file(tableFileName,'w')
    tableFile.write(date+' : '+activity+'\n')
    tableFile.write('\n')
    for line in table:
        tableFile.write(line+'\n')
    tableFile.close()

    # SHOW THE SORTED LIST IN THE LOG

    log_info(date+' : '+activity)
    for line in table:
        log_info(line)
    log_info('')

#-----------------------------------------------------------

def do_backup(v):

    write_status('backup',0,v['index'])

    args = [
        '-al',
        '-E',
        '--delete',
        '--delete-excluded',
        '--numeric-ids',
        '--one-file-system',
#       '-v',
#       '--stats',
        '--link-dest='+topdir+'/'+v['host']+'/'+v['name']+'/'+v['label']+'.1',
    ]

    src = v['src']
    dest = topdir+'/'+v['host']+'/'+v['name']+'/'+v['label']+'.0'

    # optional - "excludes" file
    excludes = topdir+'/'+v['host']+'/'+v['name']+'/excludes'
    log_debug('testing for ['+excludes+']')
    if os.path.isfile(excludes):
        log_debug('"excludes" file found, adding argument')
        args.append('--exclude-from='+excludes)

    cmd = ['/usr/bin/rsync'] + args + [src, dest]
    log_info('running >> '+(','.join(cmd)))
    startTime = datetime.datetime.now()
    (rc,stdout,stderr) = shell_capture(cmd)
    endTime = datetime.datetime.now()

    #   0      Success
    #   1      Syntax or usage error
    #   2      Protocol incompatibility
    #   3      Errors selecting input/output files, dirs
    #   4      Requested action not supported
    #   5      Error starting client-server protocol
    #   6      Daemon unable to append to log-file
    #   10     Error in socket I/O
    #   11     Error in file I/O
    #   12     Error in rsync protocol data stream
    #   13     Errors with program diagnostics
    #   14     Error in IPC code
    #   20     Received SIGUSR1 or SIGINT
    #   21     Some error returned by waitpid()
    #   22     Error allocating core memory buffers
    #   23     Partial transfer due to error
    #   24     Partial transfer due to vanished source files
    #   25     The --max-delete limit stopped deletions
    #   30     Timeout in data send/receive
    #   35     Timeout waiting for daemon connection
    complete = True if rc in (0, 24) else False
    log_debug('rc = %d, '%rc)

    prefix = topdir+'/'+v['host']+'/'+v['name']+'/'+v['label']+'.'
    if os.path.isdir(prefix+'0') == False:
        log_debug(prefix+'0 directory was not found, marking incomplete')
        complete = False

    if complete:
        log_debug('backup of '+v['host']+'/'+v['name']+' is complete')
        # "touch" the timestamp
        os.utime(prefix+'0',None)
        # rotate the numbered backups
        write_status('rotate',0,v['index'])
        if os.path.isdir(prefix+str(v['keepCount'])):
            log_debug('removing '+str(v['keepCount']))
            shutil.rmtree(prefix+str(v['keepCount']))
        rotates=[]
        for i in range(v['keepCount'],0,-1):
            if os.path.isdir(prefix+str(i-1)):
                os.rename(prefix+str(i-1),prefix+str(i))
                rotates.append(str(i-1)+'>>'+str(i))
        log_debug('rotating '+('  '.join(rotates)))
    else: # not complete
        log_debug('backup of '+v['host']+'/'+v['name']+' is complete')
        if os.path.isdir(prefix+'0'):
            log_debug('removing 0')
            shutil.rmtree(prefix+'0')

    if complete:
        v['status'] = status.SUCCEEDED
    else: # not complete
        v['status'] = status.FAILED
    v['lastBackupDurationSec'] = (endTime - startTime).seconds

    log_debug('done')

    return 1 if complete else 0

#-----------------------------------------------------------

def do_single_pass():

    write_status('thinking',0,None)
    volumes = buildVolumeTable()
    volumes = updateAgesAndSort(volumes)
    tableToLogAndDisk('thinking',volumes)

    # GO THROUGH THE LIST IN ORDER, BACKING UP EACH ONE IF NEEDED

    log_info('start of single pass')
    for volume in volumes:
        if volume['ageSec'] < volume['cycleSec']: continue
        if volume['disabled']: continue
        tableToLogAndDisk("backing up '"+volume['index']+"'", volumes)
        do_backup(volume)

    log_info('end of single pass')

    # sleep for a little bit
    for i in range(sleepMin,0,-1):
        write_status('idle',i,None)
        volumes = updateAgesAndSort(volumes)
        tableToLogAndDisk('sleeping '+str(i)+' min',volumes)
        time.sleep(60)

#-----------------------------------------------------------

# START
def main():

    # FIRST -- PARSE COMMAND LINE
    usage = "usage: %prog [options]"
    parser = OptionParser(usage)
    parser.add_option("-d", "--debug", action="store_true", dest="debug")
    parser.add_option("-q", "--quiet", action="store_true", dest="quiet")
    global options
    (options, args) = parser.parse_args()
    if len(args) != 0:
        parser.error("incorrect number of arguments")

    # SET UP SERVICES

    log_init()

    # LOOK FOR PID FILE, EXIT IF FOUND

    pidfile='/var/run/'+programName+'.pid'
    try:
        with open(pidfile) as f:
            log_info("pidfile '%s' found... better look for a running process" % pidfile)
            pid = int(f.readline())
            # Check For the existence of a unix pid, send signal 0 to it.
            try:
                os.kill(pid, 0)
            except OSError:
                log_info("pid %d not found, continuing" % pid)
            else:
                log_info("pid %d is still running, exiting" % pid)
                sys.exit()
    except IOError as e:
        pass
    file(pidfile,'w').write(str(os.getpid())+'\n')

    # SET UP SUPPORT/STATUS DIRECTORY

    mkdir_p(libdir)

    # LOOP FOREVER, WORK AND SLEEP

    while True:
        do_single_pass()

    # CLEAN UP

    log_info('cleaning up')
    os.unlink(pidfile)

#-----------------------------------------------------------

if __name__ == "__main__":
     main()


